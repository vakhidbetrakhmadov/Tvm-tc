Manual schedule parameters
Done compiling "matmul" (compile time: 155.814ms)
Execution time: 19.6134 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 155.223ms)
Execution time: 7.4134 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 146.009ms)
Execution time: 13.6109 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 159.629ms)
Execution time: 342.1066 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 143.951ms)
Execution time: 8.244 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "map" (compile time: 129.734ms)
Execution time: 14.1885 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 123.513ms)
Execution time: 5.5834 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 123.187ms)
Execution time: 5.4891 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 119.157ms)
Execution time: 5.7107 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 128.198ms)
Execution time: 5.419 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "conv2d" (compile time: 212.354ms)
Execution time: 70.7254 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 32; ++rc_outer) {
    for (int ry = 0; ry < 3; ++ry) {
      for (int rx = 0; rx < 3; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          ((__shared__ float4*)(A_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4))))[0] = (( float4*)(A + ((((((((((((int)blockIdx.z) / 12) * 917504) + ((((int)blockIdx.z) % 12) * 65536)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + (rc_outer * 2048)) + (ry * 917504)) + (rx * 65536)) + (ax3_inner_outer * 4))))[0];
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          ((__shared__ float4*)(W_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4))))[0] = (( float4*)(W + (((((((((int)blockIdx.y) * 64) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + (rc_outer * 4096)) + (ry * 393216)) + (rx * 131072)) + (ax3_inner_outer1 * 4))))[0];
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
              B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[(((((((((int)blockIdx.z) * 131072) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      B[(((((((8192 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((32 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((8224 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 195.606ms)
Execution time: 30.8274 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 2; ++rc_outer) {
    for (int ry = 0; ry < 14; ++ry) {
      for (int rx = 0; rx < 14; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 512)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (16 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 16) + (((int)threadIdx.x) * 8)) + (rc_outer * 128)) + (ry * 3584)) + (rx * 256)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            if ((((int)threadIdx.y) * 4) < (16 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-16 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              if ((((int)threadIdx.y) * 4) < (16 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-16 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (16 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-16 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 196.701ms)
Execution time: 25.0934 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 4; ++rc_outer) {
    for (int ry = 0; ry < 7; ++ry) {
      for (int rx = 0; rx < 7; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (32 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (0 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (0 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
        B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      }
      if ((((int)threadIdx.y) * 4) < (0 - ff_inner_inner_inner)) {
        B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 195.415ms)
Execution time: 45.2178 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 56; ++ry) {
    for (int rx = 0; rx < 56; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 128)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (4 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 4) + (((int)threadIdx.x) * 8)) + (ry * 896)) + (rx * 16)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          if (rc_inner < 4) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if (rc_inner < 4) {
            if ((((int)threadIdx.y) * 4) < (4 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-28 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if (rc_inner < 4) {
              if ((((int)threadIdx.y) * 4) < (4 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-28 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (4 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-28 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 195.51ms)
Execution time: 32.7095 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 28; ++ry) {
    for (int rx = 0; rx < 28; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
            A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 256)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (8 - ax3_inner_inner_s1)) {
            W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 8) + (((int)threadIdx.x) * 8)) + (ry * 1792)) + (rx * 64)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
          if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if ((((int)threadIdx.y) * 4) < (8 - ax31)) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (-24 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if ((((int)threadIdx.y) * 4) < (8 - ff_c)) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (-24 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (8 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-24 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tmm" (compile time: 155.61ms)
Execution time: 19.5252 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 153.373ms)
Execution time: 7.6691 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 171.793ms)
Execution time: 12.8445 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 170.073ms)
Execution time: 364.3569 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 155.414ms)
Execution time: 7.4927 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tbmm" (compile time: 171.555ms)
Execution time: 20.7589 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 171.939ms)
Execution time: 8.2264 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 173.998ms)
Execution time: 35.9102 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 183.967ms)
Execution time: 1954.9854 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 183.075ms)
Execution time: 10.795 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}



 - - - - 

