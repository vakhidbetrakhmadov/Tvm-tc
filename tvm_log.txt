Manual schedule parameters
Done compiling "matmul" (compile time: 501.642ms)
Execution time: 20.9993 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 488.548ms)
Execution time: 6.8734 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 504.072ms)
Execution time: 7.2695 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 416.189ms)
Execution time: 13.0424 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 517.805ms)
Execution time: 338.9156 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tmm" (compile time: 356.403ms)
Execution time: 18.5651 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 298.261ms)
Execution time: 7.1631 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 525.097ms)
Execution time: 6.9389 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 472.129ms)
Execution time: 14.3987 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 587.542ms)
Execution time: 361.7259 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tbmm" (compile time: 575.756ms)
Execution time: 8.6236 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 589.395ms)
Execution time: 10.7147 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 275.605ms)
Execution time: 12.7969 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 493.445ms)
Execution time: 15.5818 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 366.123ms)
Execution time: 27.1836 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "conv2d" (compile time: 352.864ms)
Execution time: 10.7568 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 2; ++rc_outer) {
    for (int ry = 0; ry < 14; ++ry) {
      for (int rx = 0; rx < 14; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 512)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (16 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 16) + (((int)threadIdx.x) * 8)) + (rc_outer * 128)) + (ry * 3584)) + (rx * 256)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            if ((((int)threadIdx.y) * 4) < (16 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-16 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              if ((((int)threadIdx.y) * 4) < (16 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-16 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (16 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-16 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 533.312ms)
Execution time: 8.5381 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 4; ++rc_outer) {
    for (int ry = 0; ry < 7; ++ry) {
      for (int rx = 0; rx < 7; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (32 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (0 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (0 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
        B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      }
      if ((((int)threadIdx.y) * 4) < (0 - ff_inner_inner_inner)) {
        B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 456.435ms)
Execution time: 22.8677 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 56; ++ry) {
    for (int rx = 0; rx < 56; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 128)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (4 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 4) + (((int)threadIdx.x) * 8)) + (ry * 896)) + (rx * 16)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          if (rc_inner < 4) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if (rc_inner < 4) {
            if ((((int)threadIdx.y) * 4) < (4 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-28 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if (rc_inner < 4) {
              if ((((int)threadIdx.y) * 4) < (4 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-28 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (4 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-28 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 576.863ms)
Execution time: 12.9938 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 28; ++ry) {
    for (int rx = 0; rx < 28; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
            A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 256)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (8 - ax3_inner_inner_s1)) {
            W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 8) + (((int)threadIdx.x) * 8)) + (ry * 1792)) + (rx * 64)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
          if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if ((((int)threadIdx.y) * 4) < (8 - ax31)) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (-24 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if ((((int)threadIdx.y) * 4) < (8 - ff_c)) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (-24 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (8 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-24 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 481.696ms)
Execution time: 17.2248 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 32; ++rc_outer) {
    for (int ry = 0; ry < 3; ++ry) {
      for (int rx = 0; rx < 3; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          ((__shared__ float4*)(A_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4))))[0] = (( float4*)(A + ((((((((((((int)blockIdx.z) / 12) * 917504) + ((((int)blockIdx.z) % 12) * 65536)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + (rc_outer * 2048)) + (ry * 917504)) + (rx * 65536)) + (ax3_inner_outer * 4))))[0];
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          ((__shared__ float4*)(W_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4))))[0] = (( float4*)(W + (((((((((int)blockIdx.y) * 64) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + (rc_outer * 4096)) + (ry * 393216)) + (rx * 131072)) + (ax3_inner_outer1 * 4))))[0];
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
              B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[(((((((((int)blockIdx.z) * 131072) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      B[(((((((8192 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((32 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((8224 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "map" (compile time: 529.707ms)
Execution time: 13.5796 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 401.833ms)
Execution time: 5.5364 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 523.026ms)
Execution time: 5.2123 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 446.157ms)
Execution time: 5.3119 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 469.575ms)
Execution time: 7.234 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}



 - - - - 

