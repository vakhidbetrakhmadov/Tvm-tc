Manual schedule parameters
Done compiling "matmul" (compile time: 154.633ms)
Execution time: 20.7737 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 147.884ms)
Execution time: 7.3582 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 148.554ms)
Execution time: 13.2403 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 178.279ms)
Execution time: 342.5599 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "matmul" (compile time: 163.702ms)
Execution time: 7.3479 ms
extern "C" __global__ void matmul_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int N, int M, int L) {
  if (((int)blockIdx.x) < (N / 8)) {
    if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < L; ++k) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k * M))]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < L; ++k1) {
      if ((((int)blockIdx.x) * 8) < (N - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (M - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * M) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * L) + k1)] * B[(((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) + (k1 * M))]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "map" (compile time: 124.099ms)
Execution time: 13.9315 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 134.854ms)
Execution time: 5.3008 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 129.255ms)
Execution time: 5.3628 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 120.15ms)
Execution time: 5.3549 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}


Manual schedule parameters
Done compiling "map" (compile time: 126.424ms)
Execution time: 5.475 ms
extern "C" __global__ void map_kernel0( float* __restrict__ B,  float* __restrict__ A, int M) {
  if (((int)blockIdx.x) < (M / 8)) {
    B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      B[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (A[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * 3.140000e+00f);
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "conv2d" (compile time: 197.253ms)
Execution time: 70.4523 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 32; ++rc_outer) {
    for (int ry = 0; ry < 3; ++ry) {
      for (int rx = 0; rx < 3; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          ((__shared__ float4*)(A_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4))))[0] = (( float4*)(A + ((((((((((((int)blockIdx.z) / 12) * 917504) + ((((int)blockIdx.z) % 12) * 65536)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + (rc_outer * 2048)) + (ry * 917504)) + (rx * 65536)) + (ax3_inner_outer * 4))))[0];
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          ((__shared__ float4*)(W_shared + (((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4))))[0] = (( float4*)(W + (((((((((int)blockIdx.y) * 64) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + (rc_outer * 4096)) + (ry * 393216)) + (rx * 131072)) + (ax3_inner_outer1 * 4))))[0];
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
              B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[(((((((((int)blockIdx.z) * 131072) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      B[(((((((8192 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((32 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      B[(((((((8224 + (((int)blockIdx.z) * 131072)) + (((int)blockIdx.y) * 16384)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.y) * 1024)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 256)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 197.047ms)
Execution time: 29.2318 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 2; ++rc_outer) {
    for (int ry = 0; ry < 14; ++ry) {
      for (int rx = 0; rx < 14; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 512)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (16 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 16) + (((int)threadIdx.x) * 8)) + (rc_outer * 128)) + (ry * 3584)) + (rx * 256)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            if ((((int)threadIdx.y) * 4) < (16 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-16 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              if ((((int)threadIdx.y) * 4) < (16 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-16 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (16 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-16 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 192.728ms)
Execution time: 23.9644 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 4; ++rc_outer) {
    for (int ry = 0; ry < 7; ++ry) {
      for (int rx = 0; rx < 7; ++rx) {
        __syncthreads();
        for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
        for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (32 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[(((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (rc_outer * 256)) + (ry * 7168)) + (rx * 1024)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
        __syncthreads();
        for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
          for (int ax3 = 0; ax3 < 4; ++ax3) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
          for (int ax31 = 0; ax31 < 4; ++ax31) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (0 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
          for (int ff_c = 0; ff_c < 4; ++ff_c) {
            for (int nn_c = 0; nn_c < 4; ++nn_c) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (0 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
      if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
        B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
      }
      if ((((int)threadIdx.y) * 4) < (0 - ff_inner_inner_inner)) {
        B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 192.092ms)
Execution time: 44.1452 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 56; ++ry) {
    for (int rx = 0; rx < 56; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
              A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 128)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
            }
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        if (((int)threadIdx.y) < 4) {
          for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
            if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (4 - ax3_inner_inner_s1)) {
              W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 4) + (((int)threadIdx.x) * 8)) + (ry * 896)) + (rx * 16)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
            }
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          if (rc_inner < 4) {
            A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
            if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
              A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
            }
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if (rc_inner < 4) {
            if ((((int)threadIdx.y) * 4) < (4 - ax31)) {
              W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
              if ((((int)threadIdx.y) * 4) < (-28 - ax31)) {
                W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
              }
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if (rc_inner < 4) {
              if ((((int)threadIdx.y) * 4) < (4 - ff_c)) {
                B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
                }
                if ((((int)threadIdx.y) * 4) < (-28 - ff_c)) {
                  B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                  if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                    B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (4 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-28 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "conv2d" (compile time: 196.766ms)
Execution time: 32.4998 ms
extern "C" __global__ void conv2d_kernel0( float* __restrict__ A,  float* __restrict__ W,  float* __restrict__ B) {
   float B_local[64];
  __shared__ float A_shared[512];
  __shared__ float W_shared[512];
   float A_shared_local[8];
   float W_shared_local[8];
  for (int ff_c_init = 0; ff_c_init < 4; ++ff_c_init) {
    for (int nn_c_init = 0; nn_c_init < 4; ++nn_c_init) {
      B_local[((ff_c_init * 4) + nn_c_init)] = 0.000000e+00f;
      B_local[((32 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((16 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
      B_local[((48 + (ff_c_init * 4)) + nn_c_init)] = 0.000000e+00f;
    }
  }
  for (int ry = 0; ry < 28; ++ry) {
    for (int rx = 0; rx < 28; ++rx) {
      __syncthreads();
      for (int ax3_inner_outer = 0; ax3_inner_outer < 2; ++ax3_inner_outer) {
        for (int ax3_inner_inner_s = 0; ax3_inner_inner_s < 4; ++ax3_inner_inner_s) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer * 4)) < (32 - ax3_inner_inner_s)) {
            A_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)] = A[((((((((int)threadIdx.y) * 32) + (((int)threadIdx.x) * 8)) + (ry * 7168)) + (rx * 256)) + (ax3_inner_outer * 4)) + ax3_inner_inner_s)];
          }
        }
      }
      for (int ax3_inner_outer1 = 0; ax3_inner_outer1 < 2; ++ax3_inner_outer1) {
        for (int ax3_inner_inner_s1 = 0; ax3_inner_inner_s1 < 4; ++ax3_inner_inner_s1) {
          if (((((int)threadIdx.x) * 8) + (ax3_inner_outer1 * 4)) < (8 - ax3_inner_inner_s1)) {
            W_shared[((((((int)threadIdx.y) * 64) + (((int)threadIdx.x) * 8)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)] = W[((((((((int)threadIdx.y) * 8) + (((int)threadIdx.x) * 8)) + (ry * 1792)) + (rx * 64)) + (ax3_inner_outer1 * 4)) + ax3_inner_inner_s1)];
          }
        }
      }
      __syncthreads();
      for (int rc_inner = 0; rc_inner < 8; ++rc_inner) {
        for (int ax3 = 0; ax3 < 4; ++ax3) {
          A_shared_local[ax3] = A_shared[(((((int)threadIdx.x) * 4) + (rc_inner * 64)) + ax3)];
          if ((((int)threadIdx.x) * 4) < (0 - ax3)) {
            A_shared_local[(4 + ax3)] = A_shared[(((32 + (((int)threadIdx.x) * 4)) + (rc_inner * 64)) + ax3)];
          }
        }
        for (int ax31 = 0; ax31 < 4; ++ax31) {
          if ((((int)threadIdx.y) * 4) < (8 - ax31)) {
            W_shared_local[ax31] = W_shared[(((((int)threadIdx.y) * 4) + (rc_inner * 64)) + ax31)];
            if ((((int)threadIdx.y) * 4) < (-24 - ax31)) {
              W_shared_local[(4 + ax31)] = W_shared[(((32 + (((int)threadIdx.y) * 4)) + (rc_inner * 64)) + ax31)];
            }
          }
        }
        for (int ff_c = 0; ff_c < 4; ++ff_c) {
          for (int nn_c = 0; nn_c < 4; ++nn_c) {
            if ((((int)threadIdx.y) * 4) < (8 - ff_c)) {
              B_local[((ff_c * 4) + nn_c)] = (B_local[((ff_c * 4) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[ff_c]));
              if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                B_local[((16 + (ff_c * 4)) + nn_c)] = (B_local[((16 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[ff_c]));
              }
              if ((((int)threadIdx.y) * 4) < (-24 - ff_c)) {
                B_local[((32 + (ff_c * 4)) + nn_c)] = (B_local[((32 + (ff_c * 4)) + nn_c)] + (A_shared_local[nn_c] * W_shared_local[(4 + ff_c)]));
                if ((((int)threadIdx.x) * 4) < (0 - nn_c)) {
                  B_local[((48 + (ff_c * 4)) + nn_c)] = (B_local[((48 + (ff_c * 4)) + nn_c)] + (A_shared_local[(4 + nn_c)] * W_shared_local[(4 + ff_c)]));
                }
              }
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 4; ++ff_inner_inner_inner) {
    for (int nn_inner_inner_inner = 0; nn_inner_inner_inner < 4; ++nn_inner_inner_inner) {
      if ((((int)threadIdx.y) * 4) < (8 - ff_inner_inner_inner)) {
        B[((((((int)threadIdx.y) * 128) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((ff_inner_inner_inner * 4) + nn_inner_inner_inner)];
        if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
          B[((((32 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((16 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
        }
        if ((((int)threadIdx.y) * 4) < (-24 - ff_inner_inner_inner)) {
          B[((((1024 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((32 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          if ((((int)threadIdx.x) * 4) < (0 - nn_inner_inner_inner)) {
            B[((((1056 + (((int)threadIdx.y) * 128)) + (((int)threadIdx.x) * 4)) + (ff_inner_inner_inner * 32)) + nn_inner_inner_inner)] = B_local[((48 + (ff_inner_inner_inner * 4)) + nn_inner_inner_inner)];
          }
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tmm" (compile time: 142.845ms)
Execution time: 18.9891 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 157.223ms)
Execution time: 7.126 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 154.451ms)
Execution time: 12.5417 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 170.452ms)
Execution time: 364.4392 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tmm" (compile time: 150.65ms)
Execution time: 7.1608 ms
extern "C" __global__ void tmm_kernel0( float* __restrict__ C,  float* __restrict__ A,  float* __restrict__ B, int M, int N, int K) {
  if (((int)blockIdx.x) < (M / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
    }
    for (int k = 0; k < K; ++k) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k)]));
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = 0.000000e+00f;
      }
    }
    for (int k1 = 0; k1 < K; ++k1) {
      if ((((int)blockIdx.x) * 8) < (M - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] = (C[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y))] + (A[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + k1)] * B[((((((int)blockIdx.y) * 8) + ((int)threadIdx.y)) * K) + k1)]));
        }
      }
    }
  }
}



 - - - - 

Manual schedule parameters
Done compiling "tbmm" (compile time: 159.779ms)
Execution time: 21.5123 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 169.707ms)
Execution time: 8.2726 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 159.582ms)
Execution time: 35.3688 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 176.185ms)
Execution time: 1946.9409 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}


Manual schedule parameters
Done compiling "tbmm" (compile time: 175.182ms)
Execution time: 11.799 ms
extern "C" __global__ void tbmm_kernel0( float* __restrict__ Z,  float* __restrict__ X,  float* __restrict__ Y, int B, int N, int K, int M) {
  if (((int)blockIdx.x) < (B / 8)) {
    if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
      if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
        Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
      }
    }
    for (int m = 0; m < M; ++m) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m)]));
        }
      }
    }
  } else {
    if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
      if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
        if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
          Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = 0.000000e+00f;
        }
      }
    }
    for (int m1 = 0; m1 < M; ++m1) {
      if ((((int)blockIdx.x) * 8) < (B - ((int)threadIdx.x))) {
        if ((((int)blockIdx.y) * 8) < (N - ((int)threadIdx.y))) {
          if ((((int)blockIdx.z) * 8) < (K - ((int)threadIdx.z))) {
            Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] = (Z[((((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z))] + (X[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * N) + (((int)blockIdx.y) * 8)) + ((int)threadIdx.y)) * M) + m1)] * Y[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) * K) + (((int)blockIdx.z) * 8)) + ((int)threadIdx.z)) * M) + m1)]));
          }
        }
      }
    }
  }
}



 - - - - 

